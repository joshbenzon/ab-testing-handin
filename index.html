<html lang="en">
    <head>
        <!-- Meta Information -->
        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        <!-- Font Styles -->
        <!-- DM SERIF Font -->
        <link rel="preconnect" href="https://fonts.googleapis.com" />
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
        <link
            href="https://fonts.googleapis.com/css2?family=DM+Sans:ital,opsz,wght@0,9..40,100..1000;1,9..40,100..1000&family=DM+Serif+Text:ital@0;1&display=swap"
            rel="stylesheet"
        />

        <!-- DM SANS Font -->
        <link rel="preconnect" href="https://fonts.googleapis.com" />
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
        <link
            href="https://fonts.googleapis.com/css2?family=Bree+Serif&family=DM+Sans:ital,opsz,wght@0,9..40,100..1000;1,9..40,100..1000&display=swap"
            rel="stylesheet"
        />

        <!-- Page Title -->
        <title>A/B Testing HandIn</title>

        <!-- CSS Styling -->
        <link rel="stylesheet" href="styles.css" />
    </head>

    <body>
        <!-- TITLE -->
        <section id="title">
            <h1>A/B Testing</h1>
            <p>todo</p>

            <img src="" alt="" />
        </section>

        <!-- OVERVIEW -->
        <section>
            <h2>Overview</h2>
            <p>
                In this project, I redesigned the user interface and user
                experience for the LetterBoxd app, a desktop and mobile app for
                users to see their movie reviews from their friends. I analyzed
                the user accessibility and its problems.
            </p>
            <p>
                I also created sketches, low-fidelity designs, and high-fidelity
                designs for the redesign. Then, I developed this redesign with
                HTML and CSS.
            </p>
        </section>

        <hr aria-label="outer-divider" class="outer-divider" />

        <!-- PART 1 -->
        <section>
            <h2>Part 1: Data Collection</h2>

            <section>
                <p>
                    In studio, we gather data from students from two different
                    designs: "Design A" resembled the original design and
                    "Design B" resembled my own redesign. We analyzed different
                    metrics to see which one is "better."
                </p>
                <p>
                    In regards to my design changes, I decided to "gray out" the
                    buttons that the appointment criteria did not aligned with
                    and also made the appointment that did with green. This
                    allowed users to pinpoint exactly, which appointments are
                    available given their criteria.
                </p>

                <div class="horizontal-flex">
                    <section>
                        <h3>Design A</h3>

                        <div class="image">
                            <img
                                src="./designs/Design A.png"
                                alt="Design A (Original)"
                            />
                            <p class="caption">Design A (Original)</p>
                        </div>
                    </section>

                    <hr
                        aria-label="inner-divider"
                        class="inner-divider vertical-divider"
                    />

                    <section>
                        <h3>Design B</h3>
                        <div class="image">
                            <img
                                src="./designs/Design B.png"
                                alt="Design B (Redesign)"
                            />
                            <p class="caption">Design B (Redesign)</p>
                        </div>
                    </section>
                </div>
            </section>
        </section>

        <hr aria-label="outer-divider" class="outer-divider" />

        <section>
            <h2>Part 2: Analysis</h2>

            <section>
                <h3>Creating Hypotheses</h3>

                <h4>Misclick Rate</h4>
                <h5>
                    This metric of choice resembles a boolean flag indicating if
                    the user pushed a button external to the task.
                </h5>
                <p>
                    H<sub>0</sub>: There will be no difference in the misclick
                    rate between Design A and Design B.
                </p>
                <p>
                    H<sub>1</sub>: Version A will have a higher misclick rate
                    than Version B.
                </p>
                <ul>
                    <li>
                        Because Version A has all the buttons be the same color
                        blue, there's bound to be a higher number of misclicks,
                        since there's no differentiation between what's the
                        correct button. On the other hand, Version B has a clear
                        visual green color and space differentiation with line
                        dividers to prevent users from confusing which
                        appointment and which button to press.
                    </li>
                </ul>

                <h4>Time on Page</h4>
                <h5>
                    This metric of choice resembles the otal time (in
                    milliseconds) that the user spent on the page.
                </h5>
                <p>
                    H<sub>0</sub>: There will be no difference in the time spent
                    on page between Design A and Design B.
                </p>
                <p>
                    H<sub>1</sub>: Version A will have a higher time spent on
                    the page than Version B.
                </p>
                <ul>
                    <li>
                        Because Version A has no differentiation between which
                        buttons go with which appointment slot, there's bound to
                        be more time spent on the page, as users have to read
                        each appointment description. On the other hand, Version
                        B has a clear visual green color and space
                        differentiation with line dividers to allow users to not
                        spend as much time reading appointment descriptions.
                    </li>
                </ul>

                <h4>Number of Clicks</h4>
                <h5>
                    My metric of choice resembles the number of times the user
                    clicked on the screen.
                </h5>
                <p>
                    H<sub>0</sub>: There will be no difference in the number of
                    clicks between Design A and Design B.
                </p>
                <p>
                    H<sub>1</sub>: Version A will have a higher number of clicks
                    than Version B.
                </p>
                <ul>
                    <li>
                        Because Version A has the same color and opacity levels
                        for all the buttons, there's bound to be more clicks, as
                        any button is deemed available to click from. On the
                        other hand, Version B has unavailable buttons to be
                        completely grayed out with a slight decrease in opacity
                        in order to prevent users from clicking the incorrect
                        buttons. In contrast, the correct buttons are bold and
                        visually stand out from the rest.
                    </li>
                </ul>

                <p class="extra-text">
                    Additionally, I predict for all 3 of these metrics that we
                    will reject each of the null hypothesis. Design B offers an
                    both organized differentiation with line dividers between
                    each appointment block and also a clear visual change for
                    appointments that fit the user's needs and wants (gray vs
                    green buttons). Hence, the Misclick Rate, Time on Page, and
                    the Number of Clicks will all be lower than Design A.
                </p>
            </section>

            <hr aria-label="inner-divider" class="inner-divider" />

            <section>
                <h3>Run Statistical Tests on the Data</h3>
                <h4>Misclick Rate</h4>
                <div class="image">
                    <img
                        src="./results/Result (Misclick Rate).png"
                        alt="Results of Results (Misclick Rate)"
                    />
                    <p class="caption">Summary of Results (Misclick Rate)</p>
                </div>

                <p>
                    The test we used is the "One-Tailed T-Test," because it
                    compares an experimental value (from Design B) that's either
                    bigger or smaller than a baseline number (from Design A).
                </p>
                <p>
                    Since we hypothesized that Version A's value is larger than
                    Version B, we need to take the compliment of the p-value: 1
                    - 0.9969066735 = 0.0030933265. Since the p-value of
                    0.0030933265 is less than 0.05, we reject the null
                    hypothesis. Thus, we found statistically significant
                    evidence that the alternative hypothesis is true.
                </p>
                <p>
                    Likewise in regards to the misclick rate, the average value
                    of Design A is about 0.206 rating and for Design B is 0
                    rating. Hence, since a positive value resembles "True," we
                    are confident that the hypothesis of "Version A will have a
                    higher misclick rate than Version B" is true.
                </p>

                <h4>Time on Page</h4>
                <div class="image">
                    <img
                        src="./results/Result (Time on Page).png"
                        alt="Results of Results (Time on Page)"
                    />
                    <p class="caption">Summary of Results (Time on Page)</p>
                </div>

                <p>
                    The test we used is the "One-Tailed T-Test," because it
                    compares an experimental value (from Design B) that's either
                    bigger or smaller than a baseline number (from Design A).
                </p>
                <p>
                    Since we hypothesized that Version A's value is larger than
                    Version B, we need to take the compliment of the p-value: 1
                    - 0.9751880081 = 0.0248119919. Since the p-value of
                    0.0248119919 is less than 0.05, we reject the null
                    hypothesis. Thus, we found statistically significant
                    evidence that the alternative hypothesis is true.
                </p>
                <p>
                    Likewise in regards to the time on the page, the average
                    value of Design A is about 12860 milliseconds and for Design
                    B is about 8259 milliseconds. Hence, we are confident that
                    the hypothesis of "Version A will have a higher time spent
                    on the page than Version B" is true.
                </p>

                <h4>Number of Clicks</h4>
                <div class="image">
                    <img
                        src="./results/Result (Number of Clicks).png"
                        alt="Results of Results (Number of Clicks)"
                    />
                    <p class="caption">Summary of Results (Number of Clicks)</p>
                </div>

                <p>
                    The test we used is the "One-Tailed T-Test," because it
                    compares an experimental value (from Design B) that's either
                    bigger or smaller than a baseline number (from Design A).
                </p>
                <p>
                    Since we hypothesized that Version A's value is larger than
                    Version B, we need to take the compliment of the p-value: 1
                    - 0.9331260592 = 0.0668739408. Since the p-value of
                    0.0248119919 is greater than 0.05, we fail to reject the
                    null hypothesis. Thus, we did NOT find statistically
                    significant evidence that the alternative hypothesis is
                    true.
                </p>
                <p>
                    Likewise in regards to the number of clicks, the average
                    value of Design A is about 3 clicks and for Design B is
                    about 2 clicks. Hence, we are NOT confident that the
                    hypothesis of "Version A will have a higher number of clicks
                    than Version B" is true.
                </p>
            </section>

            <hr aria-label="inner-divider" class="inner-divider" />

            <section>
                <h3>Summary Statistics</h3>
                <p>
                    When it comes to Design A, the average misclick rate is
                    about 0.206 (median: 1 & mode: 0), the average time on the
                    page is about 12860 milliseconds (median: 8223 & mode: n/a),
                    and the average number of clicks is about 3 clicks (median:
                    2 & mode: 2).
                </p>
                <p>
                    When it comes to Design B, the average misclick rate is
                    about 0 (median: 0 & mode: 0), the average time on the page
                    is about 8259 milliseconds (median: 7401 & mode: n/a), and
                    the average number of clicks is about 2 clicks (median: 2 &
                    mode: 2).
                </p>
                <p>
                    Hence, we can see that overall Design A had a higher
                    misclick rate, a higher time on the page, and higher number
                    (average and median) of clicks than Design B. Both Design A
                    and Design B have above 30 data points and a mostly equal
                    distribution (39 vs. 36).
                </p>
            </section>
        </section>

        <hr aria-label="outer-divider" class="outer-divider" />

        <!-- CONCLUSION -->
        <section id="conclusion">
            <h3>Conclusion</h3>
            <p>
                In conclusion, I found that iteration is important when
                designing and to not let "perfection be the enemy of good." I've
                also found that development constraints are important signals to
                go back to the drawing board sometimes. Finally, I found
                designing and actually developing for different screen sizes is
                a lot more complex, as it considers how different elements shift
                and even entirely disappear when transitioning.
            </p>
        </section>
    </body>
</html>
